{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [html.unescape(line.rstrip('\\n')) for line in open('./data/imdb/test_pos.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace line breaks with end of sentence\n",
    "_re1 = re.compile(r'<br /><br />', re.UNICODE)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    lines[idx] = _re1.sub(' . ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle . / and , characters \n",
    "# (behave differently for numbers are characters)\n",
    "_re1 = re.compile(r'(?<=[A-z])[\\.\\/\\,]', re.UNICODE)\n",
    "\n",
    "# replace numbers with #\n",
    "_re2 = re.compile(r'[0-9]+', re.UNICODE)\n",
    "\n",
    "# handle double occurences of #\n",
    "_re3 = re.compile(r'#[#]+', re.UNICODE)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    line = _re1.sub(' ', line)\n",
    "    line = _re2.sub('#', line)\n",
    "    lines[idx] = _re3.sub('#', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters\n",
    "_re1 = re.compile(r'[\\!\\?\\^\\*\\(\\)\\[\\]\\{\\}\\;\\:\\<\\>\\~\\_\\\\\\,]', re.UNICODE)\n",
    "\n",
    "# remove multiple (long) dashes\n",
    "_re2 = re.compile(r'.[.]+', re.UNICODE)\n",
    "\n",
    "# remove multiple (long) dashes\n",
    "_re3 = re.compile(r'-[-]+', re.UNICODE)\n",
    "\n",
    "# remove space padded hyphens\n",
    "_re4 = re.compile(r'\\s-\\s', re.UNICODE)\n",
    "\n",
    "# replace & with 'and'\n",
    "_re5 = re.compile(r'&', re.UNICODE)\n",
    "\n",
    "# replace w/ with 'with'\n",
    "_re6 = re.compile(r'w\\/', re.UNICODE)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    line = _re1.sub(' ', line)\n",
    "    line = _re2.sub(' ', line)\n",
    "    line = _re3.sub(' ', line)\n",
    "    line = _re4.sub(' ', line)\n",
    "    line = _re5.sub(' and ', line)\n",
    "    lines[idx] = _re6.sub(' with ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop backslashes\n",
    "_re1 = re.compile(r'\\\\', re.UNICODE)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    lines[idx] = _re1.sub('', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove 'www.' for uniformity\n",
    "_re1 = re.compile(r'www.', re.UNICODE)\n",
    "\n",
    "# replace complicated urls with homepage\n",
    "_re2 = re.compile(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', re.UNICODE)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    line = _re1.sub('', line)\n",
    "    url = _re2.findall(line)\n",
    "    if url:\n",
    "        lines[idx] = _re2.sub(url[0][1], line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad quotes (non-apostrophe) with space\n",
    "_re1 = re.compile(r\"(?<![a-z])[\\']\", re.UNICODE)\n",
    "_re2 = re.compile(r\"[\\'](?![a-z])\", re.UNICODE)\n",
    "_re3 = re.compile(r'\\\"', re.UNICODE)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    line = _re1.sub(' ', line)\n",
    "    line = _re2.sub(' ', line)\n",
    "    lines[idx] = _re3.sub(' \" ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# omit double+ occurences (spaces etc.)\n",
    "_re1 = re.compile(r'\\s[\\s]+', re.UNICODE)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    lines[idx] = _re1.sub(' ', line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_pos.txt', 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(f'{line.lower()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" or load pre-trained retrogram embeddings\\nem = np.load('./data/...')\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" train a skipgram model from scratch\n",
    "import gensim\n",
    "corpus = load...\n",
    "\n",
    "model = gensim.models.Word2Vec(corpus, size=100)\n",
    "em = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" or load pre-trained retrogram embeddings\n",
    "em = np.load('./data/...')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, embeddings, dims=300):\n",
    "        self.embeddings = embeddings\n",
    "        self.dims = dims\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.embeddings[w] for w in words if w in self.embeddings]\n",
    "                    or [np.zeros(self.dims)], axis=0) for words in X])\n",
    "\n",
    "vectorizer = MeanEmbeddingVectorizer(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit_transform(x)\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.fit_transform(x_)\n",
    "y_test = y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
